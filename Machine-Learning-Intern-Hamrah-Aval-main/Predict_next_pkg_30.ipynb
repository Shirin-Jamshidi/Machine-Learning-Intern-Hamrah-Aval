{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lqdt-kjAE-vo"
      },
      "source": [
        "#All"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nz9gMBH9Dce"
      },
      "source": [
        "#####Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbkuQLeD8sUz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import imageio\n",
        "import os\n",
        "from skimage import io\n",
        "from IPython.display import Image\n",
        "from PIL import Image\n",
        "from scipy.signal import correlate2d\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mHzTp1ps9OLF"
      },
      "source": [
        "#####Read file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vnljzYb9RlW",
        "outputId": "908a9a82-df78-4805-ec56-ddbbe3b4405b"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(r\"30.csv\")\n",
        "print(df)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M-S8wpV599bt"
      },
      "source": [
        "#####find uniqe sub_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJzgB8yd_SCs",
        "outputId": "f89a3aad-56e1-4803-e150-79684d86ad28"
      },
      "outputs": [],
      "source": [
        "# Extract the unique IDs from the 'sub_id' column\n",
        "unique_ids = df['sub_id'].unique()\n",
        "\n",
        "# Print the unique IDs\n",
        "for unique_id in unique_ids:\n",
        "    print(unique_id)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Trjl7pMB_vRH"
      },
      "source": [
        "####how many uniqe id buy package and save data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "B1aaWBYAMAKQ"
      },
      "source": [
        "#####count every user has how many pkg purchase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAZ_tIl0_u3M",
        "outputId": "632e2399-3f0d-4d10-8d5f-7f103a49355e"
      },
      "outputs": [],
      "source": [
        "# Count the occurrences of each unique ID\n",
        "id_counts = df['sub_id'].value_counts()\n",
        "\n",
        "# Print the ID counts\n",
        "for unique_id, count in id_counts.items():\n",
        "    print(f\"Unique ID: {unique_id}, Count: {count}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "u1X1eWhKMXgh"
      },
      "source": [
        "##### plot data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "fqeXPm7-BP9D",
        "outputId": "5af6d8b1-9d91-4f52-a48a-bfb8afa2026f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "# Plotting the histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(id_counts, bins=100, alpha=0.75, color='blue')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Count of Unique IDs')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WfgFWCPFCo0x"
      },
      "source": [
        "##### create csv file for every unique id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl8fmrrNTKRd",
        "outputId": "0d5e6e19-682a-44ce-f9a9-91cd4900b4d6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "#first delete\n",
        "!rm -r 'unique_id_behavior'\n",
        "#then create folder\n",
        "# Create the folder if it doesn't exist\n",
        "folder_name = 'unique_id_behavior'\n",
        "if not os.path.exists(folder_name):\n",
        "    os.makedirs(folder_name)\n",
        "\n",
        "# Create a dictionary to store lists for each unique ID\n",
        "id_lists = {unique_id: [] for unique_id in id_counts.index}\n",
        "\n",
        "# Iterate over each row and append to the corresponding list\n",
        "for index, row in df.iterrows():\n",
        "    sub_id = row['sub_id']\n",
        "    id_lists[sub_id].append(row.tolist())\n",
        "\n",
        "minimum_data_needed = 15\n",
        "# Save each list as a separate CSV file in the folder\n",
        "for unique_id, rows_list in id_lists.items():\n",
        "    if len(rows_list) >= minimum_data_needed:\n",
        "        # Create a DataFrame from the list of rows\n",
        "        sub_df = pd.DataFrame(rows_list, columns=df.columns)\n",
        "\n",
        "        # Sort the DataFrame based on the \"actvn_dt\" column\n",
        "        sub_df = sub_df.sort_values(by='actvn_dt')\n",
        "\n",
        "        # Add a new column \"times\" with incrementing values starting from 1\n",
        "        sub_df['times'] = range(1, len(sub_df) + 1)\n",
        "\n",
        "        # Save the DataFrame as a CSV file in the folder\n",
        "        file_path = os.path.join(folder_name, f'{unique_id}_30.csv')\n",
        "        sub_df.to_csv(file_path, index=False)\n",
        "        print(f'Saved rows for Unique ID {unique_id} in {file_path}')\n",
        "    else:\n",
        "        print(f'Skipped saving rows for Unique ID {unique_id} (less than {minimum_data_needed} rows)')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xQTJzeBjNRRg"
      },
      "source": [
        "##### make it zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYDrjsOeEYbn",
        "outputId": "ea87d614-89da-4ea2-eb21-acdbc819beaa"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "# Create a zip file of the folder\n",
        "zip_file_name = 'unique_id_behavior.zip'\n",
        "with zipfile.ZipFile(zip_file_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, _, files in os.walk(folder_name):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            zipf.write(file_path, os.path.basename(file_path))\n",
        "\n",
        "print(f'Successfully created {zip_file_name}.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eco1tyQyNZzw"
      },
      "source": [
        "#### train and predict last bought"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cDFPgh3Ax-Jh"
      },
      "source": [
        "#####predict next pkg linear reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfgMG8nz6Zuo"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def predict_next_pkg_linear(X_train,y_train,next_time):\n",
        "    encoder = OneHotEncoder()\n",
        "\n",
        "    # Fit the encoder to the 'voice_pkg_code' column\n",
        "    encoder.fit(y_train.reshape(-1, 1))\n",
        "\n",
        "    # Transform the 'voice_pkg_code' column into one-hot encoded features\n",
        "    encoded_features = encoder.transform(y_train.reshape(-1, 1)).toarray()\n",
        "    # print(encoded_features)\n",
        "    # Scale the X_train data\n",
        "    sc_X = StandardScaler()\n",
        "    X_train_scaled = sc_X.fit_transform(X_train.reshape(-1, 1))\n",
        "\n",
        "    lin_reg = LinearRegression()\n",
        "    lin_reg.fit(X_train_scaled, encoded_features)\n",
        "\n",
        "    # Perform decoding\n",
        "    predicted_features = lin_reg.predict(sc_X.transform(np.array([next_time]).reshape(-1, 1)))\n",
        "    # print(predicted_features)\n",
        "    decoded_labels = encoder.inverse_transform(predicted_features)\n",
        "    # print(int(decoded_labels[0][0]))\n",
        "    return decoded_labels\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk7GaOYiNyXf"
      },
      "source": [
        "#####Read files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O8XOzPwmrXa"
      },
      "outputs": [],
      "source": [
        "# Get a list of all CSV files in the folder\n",
        "csv_files = [file for file in os.listdir(folder_name) if file.endswith('.csv')]\n",
        "real_data = []\n",
        "predict_nex_pkg_data = []\n",
        "# Read each CSV file one by one\n",
        "for file in csv_files:\n",
        "    # Construct the file path\n",
        "    file_path = os.path.join(folder_name, file)\n",
        "\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Get information\n",
        "    X_train = df[\"times\"].values.reshape(-1, 1)\n",
        "    # X_train = df[[\"actvn_dt\", \"times\"]].values.reshape(-1, 1)\n",
        "    X_train = np.delete(X_train, -1)\n",
        "    # X_train = df[\"actvn_dt\"].values.reshape(-1, 1)\n",
        "    y_train = df[\"voice_pkg_code\"].values.reshape(-1, 1)\n",
        "    y_train = np.delete(y_train, -1)\n",
        "\n",
        "    sub_id = df[\"sub_id\"].iloc[-1]\n",
        "    next_time = df[\"times\"].iloc[-1]\n",
        "    last_pkg_bought = df[\"voice_pkg_code\"].iloc[-1]\n",
        "    real_data.append( df[\"voice_pkg_code\"].iloc[-1])\n",
        "    # print(sub_id)\n",
        "    # Predict\n",
        "    decoded_labels = predict_next_pkg_linear(X_train,y_train , next_time)\n",
        "    # if(last_pkg_bought != int(decoded_labels[0][0])):\n",
        "      # print(f'{sub_id}  last pkg bought : {last_pkg_bought}  next pkg predicted {int(decoded_labels[0][0])}.')\n",
        "    predict_nex_pkg_data.append(int(decoded_labels[0][0]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkQ3_ISW7So5",
        "outputId": "3be170e0-8b8e-4d72-ccdb-abe86069074d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score,precision_score, recall_score\n",
        "print(\"accuracy_score = \",accuracy_score(real_data,predict_nex_pkg_data))\n",
        "print(confusion_matrix(real_data, predict_nex_pkg_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "7UCMVgSZsqA4",
        "outputId": "b5049f02-b7aa-461f-e312-28cd5cf060be"
      },
      "outputs": [],
      "source": [
        "# Plot the histograms\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.hist(predict_nex_pkg_data, bins=160, color='blue', alpha=0.5, label='predict')\n",
        "plt.hist(real_data, bins=160, color='red', alpha=0.5, label='last bought')\n",
        "\n",
        "plt.xlabel('voice_pkg_code')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('predict with linear regresion and ')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EaaDr7rj2ZjC"
      },
      "source": [
        "#### train and predict every user with times"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kG6O25Fb2ZjD"
      },
      "source": [
        "#####predict next pkg linear reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUYkrclB2ZjE"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def predict_next_pkg_linear(X_train,y_train,next_time):\n",
        "    encoder = OneHotEncoder()\n",
        "\n",
        "    # Fit the encoder to the 'voice_pkg_code' column\n",
        "    encoder.fit(y_train.reshape(-1, 1))\n",
        "\n",
        "    # Transform the 'voice_pkg_code' column into one-hot encoded features\n",
        "    encoded_features = encoder.transform(y_train.reshape(-1, 1)).toarray()\n",
        "\n",
        "    # Scale the X_train data\n",
        "    sc_X = StandardScaler()\n",
        "    X_train_scaled = sc_X.fit_transform(X_train.reshape(-1, 1))\n",
        "\n",
        "    lin_reg = LinearRegression()\n",
        "    lin_reg.fit(X_train_scaled, encoded_features)\n",
        "\n",
        "    # Perform decoding\n",
        "    predicted_features = lin_reg.predict(sc_X.transform(np.array([next_time]).reshape(-1, 1)))\n",
        "    decoded_labels = encoder.inverse_transform(predicted_features)\n",
        "    return decoded_labels\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eNgUnlxt2ZjE"
      },
      "source": [
        "#####Read files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTRck9VI2ZjE",
        "outputId": "63bc3bc8-5330-4f5c-cef1-0fe2b0ff2298"
      },
      "outputs": [],
      "source": [
        "# Get a list of all CSV files in the folder\n",
        "csv_files = [file for file in os.listdir(folder_name) if file.endswith('.csv')]\n",
        "real_data = []\n",
        "predict_nex_pkg_data = []\n",
        "# Read each CSV file one by one\n",
        "for file in csv_files:\n",
        "    # Construct the file path\n",
        "    file_path = os.path.join(folder_name, file)\n",
        "\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Get information\n",
        "    X_train = np.ravel(np.array(df[\"times\"].values).reshape(-1, 1))\n",
        "    # X_train = np.ravel(np.array(df[\"actvn_dt\"].values).reshape(-1, 1))\n",
        "    y_train = np.ravel(np.array(df[\"voice_pkg_code\"].values).reshape(-1, 1))\n",
        "    sub_id = df[\"sub_id\"].iloc[-1]\n",
        "    next_time = df[\"times\"].iloc[-1] + 1\n",
        "    last_pkg_bought = df[\"voice_pkg_code\"].iloc[-1]\n",
        "    real_data.append( df[\"voice_pkg_code\"].iloc[-1])\n",
        "\n",
        "    # Predict\n",
        "    decoded_labels = predict_next_pkg_linear(X_train,y_train , next_time)\n",
        "    if(last_pkg_bought != int(decoded_labels[0][0])):\n",
        "      print(f'{sub_id}  last pkg bought : {last_pkg_bought}  next pkg predicted {decoded_labels}.')\n",
        "    predict_nex_pkg_data.append(int(decoded_labels[0][0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "1AevCqPY2ZjF",
        "outputId": "a20563d3-8abf-41a8-a017-7c871f9f4a64"
      },
      "outputs": [],
      "source": [
        "# Plot the histograms\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.hist(predict_nex_pkg_data, bins=160, color='blue', alpha=0.5, label='predict')\n",
        "plt.hist(real_data, bins=160, color='red', alpha=0.5, label='last bought')\n",
        "\n",
        "plt.xlabel('voice_pkg_code')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('predict with linear regresion and ')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
